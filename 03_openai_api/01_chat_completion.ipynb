{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5af71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv  # .env 파일의 환경변수 로드\n",
    "import os                       # 환경변수 접근용\n",
    "\n",
    "load_dotenv()                   # 현재 위치의 .env를 읽어와 환경변수로 등록\n",
    "api_key=os.getenv(\"openai_key\") # .env의 openai_key 값을 가져옴\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c63b0f",
   "metadata": {},
   "source": [
    "## 대화내역 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f3d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-D3bb24rxEJpA1L83P6gENpBCKR3Yv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='물론이지!  \\n\\n1. GPT는 트랜스포머의 디코더 구조를 기반으로 대규모 텍스트를 사전학습한 언어 모델이야.  \\n2. 모델 크기와 학습 데이터가 커지면서 자연스러운 언어 생성과 다양한 작업 수행 능력이 향상됐어.  \\n3. 그래서 별도 미세조정 없이도 여러 작업을 할 수 있는 제로샷·원샷 학습 능력을 갖췄어.  \\n\\n필요하면 더 간단하게도 정리해줄게!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1769751876, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_e01c6f58e1', usage=CompletionUsage(completion_tokens=122, prompt_tokens=608, total_tokens=730, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model= 'gpt-4.1-mini' ,\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',                    # 시스템 역할: 챗봇의 성격/규칙 지정\n",
    "            'content': '너는 친절한 챗봇입니다.'  # 친절한 톤으로 응답하도록 지시\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',                      # 사용자 발화 1\n",
    "            'content': '안녕, 나는 LLM을 공부하는 학생이야. 반갑다~'\n",
    "        },\n",
    "        {\n",
    "            'role': 'assistant',                 # (이전 대화가 있었다는 가정) 어시스턴트의 답변을 히스토리로 제공\n",
    "            'content': '안녕! 만나서 반가워~ LLM 공부하고 있다니 멋지다! 어떤 분야에 관심이 있는지 말해줄래? 내가 도움이 될 수 있으면 좋겠어.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',                      # 사용자 발화 2(질문)\n",
    "            'content': 'gpt모델은 트랜스포머로부터 어떻게 발전된거야?'\n",
    "        },\n",
    "        {\n",
    "            'role': 'assistant',                 # (이전 답변) 긴 설명을 히스토리로 제공\n",
    "            'content': '''\n",
    "좋은 질문이야! GPT 모델은 트랜스포머(Transformer) 아키텍처를 기반으로 발전했어. 간단히 설명할게.\n",
    "\n",
    "1. **트랜스포머(Transformer)**\n",
    "2017년에 \"Attention is All You Need\" 논문에서 소개된 트랜스포머는 자연어 처리의 혁신적인 모델 구조야. 이전 RNN이나 LSTM과 달리, 순차적인 계산 없이도 병렬 처리가 가능하고, '셀프 어텐션(Self-Attention)' 메커니즘을 사용해 문맥을 효율적으로 이해할 수 있어.\n",
    "\n",
    "2. **GPT (Generative Pre-trained Transformer)**\n",
    "GPT는 트랜스포머의 '디코더' 부분을 기반으로 한 모델이야. OpenAI가 처음 발표한 GPT는 대규모 텍스트 데이터에 대해 '언어 모델링' 방식으로 사전학습(pre-training)을 하고, 이후 특정 작업에 맞게 미세조정(fine-tuning)하는 방식을 사용했어.\n",
    "\n",
    "3. **주요 발전 포인트**\n",
    "- **사전학습과 미세조정**: GPT는 트랜스포머를 이용해 방대한 텍스트를 예측하는 작업으로 사전학습하고, 이후 다양한 언어 처리 작업에 적용할 수 있어.\n",
    "- **규모 확장**: GPT-2, GPT-3, 그리고 최신 GPT-4로 갈수록 모델 크기와 학습 데이터 양이 크게 늘어나면서, 더 자연스럽고 다재다능한 언어 능력을 갖추게 됐어.\n",
    "- **제로샷/원샷 학습 능력**: 큰 모델로 발전하면서 GPT는 별도 미세조정 없이도 (제로샷) 또는 적은 예시만으로도 (원샷/퓨샷) 다양한 작업을 수행할 수 있게 되었어.\n",
    "\n",
    "정리하자면, GPT는 트랜스포머 아키텍처의 강력한 특징들을 활용해, 대규모 사전학습과 점차 확장된 모델 크기를 통해 자연어 생성 및 이해 능력을 크게 향상시킨 모델이라고 할 수 있어.\n",
    "\n",
    "더 궁금한 점 있으면 언제든 물어봐!\n",
    "'''    \n",
    "        },\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : \"와 대단하구나! 세 줄로 요약해줘.\"\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    temperature = 1,               # 생성 다양성(높을수록 창의적)\n",
    "    top_p = 1,                     # Top-p 샘플링 범위 (1이면 제한없음)\n",
    "    max_completion_tokens = 4096,  # 최대 출력 토큰 수\n",
    "\n",
    ")\n",
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e1d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이지!  \n",
      "\n",
      "1. GPT는 트랜스포머의 디코더 구조를 기반으로 대규모 텍스트를 사전학습한 언어 모델이야.  \n",
      "2. 모델 크기와 학습 데이터가 커지면서 자연스러운 언어 생성과 다양한 작업 수행 능력이 향상됐어.  \n",
      "3. 그래서 별도 미세조정 없이도 여러 작업을 할 수 있는 제로샷·원샷 학습 능력을 갖췄어.  \n",
      "\n",
      "필요하면 더 간단하게도 정리해줄게!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d10036",
   "metadata": {},
   "source": [
    "# 사용자 입력을 반복적으로 받아 대화하는 챗봇\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fb7038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료하려면, exit를 입력하세요\n",
      "\n",
      "대화를 종료한다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system', 'content': '당신은 지혜로운 챗봇입니다.'}    \n",
    "]\n",
    "\n",
    "print('종료하려면, exit를 입력하세요\\n')\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    \n",
    "    if user_input.lower().strip() == 'exit':\n",
    "        print('대화를 종료한다.')\n",
    "        break\n",
    "    \n",
    "    messages.append({'role' : 'user', 'content' : user_input})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        messages = messages,\n",
    "        temperature = 1,\n",
    "        top_p= 1,\n",
    "        max_completion_tokens= 4097    \n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message.content\n",
    "    print(f\"Assietant: {assistant_message}\")\n",
    "    messages.append({'role': 'assistant', 'content': assistant_message})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0af5",
   "metadata": {},
   "source": [
    "- 서비스에서 대화 저장을 처리하는 방식\n",
    "    - DB에 저장(일반적)\n",
    "        - RDB(PostgreSQL/MySQL) : 유저/세션/메시지 관계를 함께 저장\n",
    "        - NoSQL(MongoDB 등) : 문서 형태로 대화를 한번에 저장\n",
    "    - 캐시에 저장(속도) + DB에 영구 저장(혼합)\n",
    "        - Redis에 최근 N개의 메시지를 캐시로 두고 빠르게 응답\n",
    "        - 일정 주기/이벤트 기준으로 DB에 영구 저장\n",
    "    - 파일에 저장\n",
    "        - JSON 파일 등으로 로컬에 저장\n",
    "        - 붙여서 사용하는 가벼운 DB가 파일 형태로 저장되는 경우\n",
    "        \n",
    "- 서비스 운영시에 고려사항\n",
    "    - 전체 대화를 매번 모델에 다 보내게 되면 비용/속도 문제가 생긴다.\n",
    "        - 그래서 최근 N개만 보낸다거나.\n",
    "        - 중간 중간에 요약(summary)을 만들어 저장하고 요약본 + 최근 대화 형태로 컨텍스트 구성\n",
    "    - 개인정보\n",
    "        - DB 접근 암호화, 로그 마스킹\n",
    "        - API/KEY 등은 대화메시지에 저장하지 않음\n",
    "    - RAG 같은 검색형 기능들을 추가할 경우\n",
    "        - 전체 대화를 DB에 저장 + 중요한 메시지는 벡터 DB에 임베딩 저장해서 예전에 대화했던 내용과 관련된 내용이 나오면 검색해서\n",
    "          컨텍스트에 추가 해준다.\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f64171",
   "metadata": {},
   "source": [
    "# Chat Completions를 스트리밍으로 받아 한 글짜씩 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82f39e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "알겠어! 스트림 테스트를 위한 아주 긴 답변을 준비해볼게. 다양한 주제를 폭넓게 다루면서 글을 길게 이어나가 보겠다.\n",
      "\n",
      "---\n",
      "\n",
      "인간의 역사와 문화, 과학의 발전, 그리고 우주의 신비에 이르기까지 우리가 걸어온 길은 참으로 복잡하고도 아름답다. 인류는 수만 년 전부터 도구를 만들고, 언어를 발전시키며, 공동체를 이루어 살아왔다. 초기 인류는 불을 발견하고, 사냥과 채집을 통해 생존의 터전을 마련했고, 농업 혁명을 통해 정착 생활을 시작했다. 이를 바탕으로 문명이 꽃피기 시작했으며, 도시가 세워지고 문자가 발명되면서 지식과 문화가 축적되기 시작했다.\n",
      "\n",
      "고대 문명 중 하나인 메소포타미아, 즉 오늘날의 이라크 지역에서 발달한 수메르 문명은 인류 최초의 도시 국가들과 쐐기문자를 탄생시켰다. 이들은 법률을 제정하고, 수학과 천문학의 기초를 다졌으며, 종교와 예술을 통해 세상을 해석하려 했다. 이집트 문명 역시 황하와 나일강 주변에서 번성하며 피라미드와 미라 같은 독특한 문화유산을 남겼다. 고대 그리스에서는 철학과 민주주의, 그리고 과학적 사고가 발전했으며, 수많은 위대한 사상가들이 등장했다.\n",
      "\n",
      "중세를 지나 근대에 이르러서는 르네상스와 계몽주의의 시기를 맞이하며 인간 중심의 사고와 함께 과학 혁명이 일어났다. 코페르니쿠스와 갈릴레이 같은 천문학자들은 지동설을 제시하며 우주에 대한 이해를 확장시켰고, 뉴턴은 만유인력의 법칙을 발견해 물리학의 토대를 다졌다. 산업 혁명은 기술과 경제 구조를 근본적으로 변화시켜 도시화와 자본주의 체제를 촉진했다.\n",
      "\n",
      "20세기에는 두 차례의 세계 대전과 냉전, 그리고 우주 경쟁을 경험했다. 컴퓨터와 인터넷의 발명은 정보의 홍수 시대를 열었고, 인공지능과 빅데이터, 생명공학 등 첨단 기술들이 우리의 생활 방식을 재편하고 있다. 동시에 환경 문제와 인구 증가, 자원 고갈 같은 전 지구적 도전도 계속되고 있어 인류는 지속 가능한 미래를 고민해야 하는 상황에 직면해 있다.\n",
      "\n",
      "우주에 대한 탐구는 인류의 호기심과 도전 정신을 잘 보여준다. 지구 궤도를 벗어나 달에 착륙하고, 화성 탐사선이 그 행성을 조사하며, 태양계를 넘어서 외계 행성을 찾아 나서는 등의 노력은 과학과 기술의 정점이라 할 수 있다. 아직 많은 미지의 영역이 존재하지만, 이러한 탐사 활동은 우리 존재에 대한 근본적인 질문에 답하는 데 기여할 것이다.\n",
      "\n",
      "문화적으로도 우리는 다양한 문명과 사상을 통해 서로를 이해하고 배우는 기회를 갖게 되었다. 언어와 예술, 종교와 철학은 인간 경험의 다채로운 표현이며, 이를 통해 우리는 자신과 타인을 더 깊이 이해할 수 있다. 인류의 다양성은 갈등과 도전도 함께하지만, 궁극적으로는 공존과 협력의 가치를 배우는 과정이기도 하다.\n",
      "\n",
      "이처럼 긴 세월 동안 축적된 지식과 경험은 오늘날 우리의 삶을 형성하고 있으며, 앞으로도 인류는 끊임없이 배우고 성장하면서 더 나은 세상을 만들어 나갈 것이다. 끝없이 변화하는 세상 속에서 진리와 가치를 찾고, 서로를 돕고 존중하는 태도가야말로 우리가 나아가야 할 길일 것이다.\n",
      "\n",
      "---\n",
      "\n",
      "이 정도면 스트림 테스트에 충분할 거야! 더 필요하면 언제든 말해줘."
     ]
    }
   ],
   "source": [
    "# 스트림처리 : 응답을 한번에 받지 않고 조각(chunk) 단위로 실시간 수신\n",
    "stream = client.chat.completions.create(\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages= [{'role' : 'user', 'content' : '나 스트림테스트 할 거니까, 아주 긴 답변을 해줘.'}],\n",
    "    max_completion_tokens= 2000,\n",
    "    stream=True             # .스트리밍 모드 활성화(True면 chunk 단위로 변환)\n",
    ")\n",
    "\n",
    "for chunk in stream:        # 스트림에서 chunk를 하나씩 순회하면서 수신\n",
    "    content = chunk.choices[0].delta.content    # 이번 chunk에 새로 추가된 텍스트(delta)만 추출\n",
    "    if content is not None:                     \n",
    "        print(content, end='')                  # 줄바꿈 없이 이어붙임\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd69e0",
   "metadata": {},
   "source": [
    "### 스트리밍 응답으로 실시간 출력되는 콘솔 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료하려면, exit를 입력하세요\n",
      "\n",
      "Assistant: 힘드신가 봐요. 무엇 때문에 집에 가고 싶은지 이야기해 주실래요? 도움이 될 수 있도록 들어드릴게요.\n",
      "Assistant: 너무 졸리면 휴식이 필요하겠네요. 가능하다면 잠깐이라도 눈을 붙이거나 편안하게 쉬는 시간을 가져보세요. 몸과 마음이 좀 더 나아질 거예요. 도움이 필요하면 언제든 말씀해 주세요!\n",
      "대화를 종료한다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role' : 'system', 'content': '당신은 지혜로운 챗봇입니다.'}    \n",
    "]\n",
    "\n",
    "print('종료하려면, exit를 입력하세요\\n')\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input('User: ')\n",
    "    \n",
    "    if user_input.lower().strip() == 'exit':\n",
    "        print('대화를 종료한다.')\n",
    "        break\n",
    "    \n",
    "    messages.append({'role' : 'user', 'content' : user_input})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4.1-mini',\n",
    "        messages = messages,\n",
    "        temperature = 1,\n",
    "        top_p= 1,\n",
    "        max_completion_tokens= 4096,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # 스트림 출력처리 : chunk가 도착할때마다 바로 출력하고 전체 답변을 누적\n",
    "    print(f\"Assistant: \", end='')\n",
    "    assistant_message = ''                          # 전체 답변을 누적할 변수\n",
    "    for chunk in response:                          # 스트리밍 모드로 도착한 chunk 단위로 순회\n",
    "        content = chunk.choices[0].delta.content    # 이번 chunk에 새로 추가된 텍스트(delta)만 추출\n",
    "        if content is not None:\n",
    "            print(content, end='')                  # 줄바꿈 없이 실시간으로 이어서 출력\n",
    "            assistant_message += content            #\n",
    "            \n",
    "    print()\n",
    "\n",
    "    messages.append({'role': 'assistant', 'content': assistant_message}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2d27c",
   "metadata": {},
   "source": [
    "# token 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e03f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\nlp\\nlp_venv\\lib\\site-packages (from tiktoken) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "   ---------------------------------------- 0.0/878.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 878.7/878.7 kB 9.8 MB/s  0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fbb4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'cl100k_base'>\n",
      "14\n",
      "<Encoding 'o200k_base'>\n",
      "10\n",
      "<Encoding 'o200k_base'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken # 텍스트를 토큰 단위로 인코딩/계산하는 OpenAI 토크나이저 라이브러리\n",
    "\n",
    "gpt35 = tiktoken.encoding_for_model('gpt-3.5')              # GPT3.5에 대응되는 인코딩(토크나이저) 가져옴\n",
    "print(gpt35)\n",
    "print(len(gpt35.encode('아버지가 방에 들어가십니다.')))      # 문장을 토큰으로 쪼갠 뒤 토큰 개수 확인\n",
    "\n",
    "gpt4o = tiktoken.encoding_for_model('gpt-4o')               # \n",
    "print(gpt4o)\n",
    "print(len(gpt4o.encode('아버지가 방에 들어가십니다.')))\n",
    "\n",
    "gpt41 = tiktoken.encoding_for_model('gpt-4.1')\n",
    "print(gpt41)\n",
    "print(len(gpt41.encode('아버지가 방에 들어가십니다.')))\n",
    "\n",
    "# gpt52 = tiktoken.encoding_for_model('gpt-5.2')    # tiktoken에 매핑 정보가 없으면 keyError가 발생 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39bb6dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- 3월 22일 코스피 지수가 장중 5000포인트를 돌파하며 사상 최고치를 기록.\\n- 국제 금값도 이달에만 14% 이상 상승해 22일 트라이온스당 4900달러를 넘어섰고, 5000달러 돌파를 눈앞에 둠.\\n- 국내 금값도 역대 최고가를 경신, 금 1돈(3.75g)당 약 88만원에 거래됨.\\n- 은값도 올해 37% 이상 상승해 99달러에 도달.\\n- 금값 상승 배경: 도널드 트럼프 미국 대통령의 예측 불가능한 행보, 화폐가치 하락 우려에 따른 투자자 및 중앙은행의 금 매수세 증가.\\n- 금값은 최근 4거래일 연속 큰 폭으로 상승하며 4500달러에서 4900달러까지 빠르게 올랐음.\\n- 금의 수익률은 올해 1월 한 달간 14.6% 상승해 주요 주가지수 및 반도체지수 수익률을 상회.\\n- 국내 금값도 23일 한국거래소에서 g당 23만4100원, 금 1돈당 87만7800원으로 최고가 경신.\\n- 민간 금거래소에서는 금 매입가가 1돈당 100만원을 넘기도 함.\\n- 과거 10월 금투자 열풍 당시 ‘김치프리미엄’(국내 금값과 국제 금값 차이)이 두 자릿수였으나, 현재는 약 1% 수준으로 정상화.\\n- 이번 금값 상승은 가격 거품이 아닌 실제 수요 증가와 가치 상승에 따른 것임.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "지난 22일 코스피 지수가 마침내 ‘꿈의 지수’인 5000포인트를 장중 돌파하며 새 역사를 썼습니다. 매일 신고가를 쓰는 코스피, 삼성전자, 현대차에 가려져있지만 국내 증시 못지 않게 오르는 자산이 ‘금’입니다.\n",
    "\n",
    "국제 금값은 이달에만 14% 넘게 오르면서 22일(현지시간) 트라이온스당 4900달러를 돌파했습니다. 금 역시 역사적인 5000달러를 코앞에 두고 있죠. 국내 금값 역시 최근 역대 최고가를 경신하며 한 돈(3.75g)당 88만원 수준까지 올랐습니다. 은은 올해 37% 넘게 오르면서 99달러까지 오른 상태입니다.\n",
    "\n",
    "국제 금값이 해외 투자은행(IB)이 지난해 예상한 수준을 단박에 넘어서면서 골드만삭스 등은 금값의 목표수준을 높이고 있습니다.\n",
    "\n",
    "금값이 상승하는 배경엔 예상하기 어려운 도널드 트럼프 미국 대통령의 행보, 화폐가치 하락을 피해 자산을 보유하려는 투자자와 중앙은행의 매수세가 깔려있습니다. 최근 흐름을 짚어봤습니다. 올해 코스피가 초강세를 보이며 매 거래일마다 백단위 숫자가 바뀌었습니다. 최근 금값도 마찬가지입니다. 지난 16일 4500달러선에 머물던 금은 19일 4600달러, 20일 4700달러, 21일 4800달러, 22일 4900달러를 넘기며 4거래일 연속 앞자리를 바꾸는 강세를 이어갔습니다.\n",
    "\n",
    "금은 올해 1월 20여일간 14.6% 가량 오른 겁니다. 그간 많이 올랐다는 필라델피아 반도체지수(13.7%)는 물론 세계 주요 주가지수를 압도하는 수익률입니다. 18% 오른 코스피를 제외하곤 금 투자가 수익률 측면에선 상당히 높았던 셈입니다. 지난 1년전과 비교해도 금값은 79.8%나 상승했습니다.\n",
    "\n",
    "국내 금값도 23일엔 한국거래소에서 g당 2% 23만4100원에 마감해 역대 최고가를 경신했습니다. 금 한 돈당 87만7800원에 달합니다. 민간금거래소에선 이미 금 매입가가 한 돈당 100만원을 웃돕니다.\n",
    "\n",
    "지난 10월엔 금투자 열풍이 불면서 ‘김치프리미엄(국내가격-국제가격)’이 두자릿 수에 달할 정도로 가격에 거품이 꼈었지만, 이번엔 다릅니다.\n",
    "\n",
    "현재 김치프리미엄은 1% 남짓입니다. 당시 일일 거래대금이 5000억원을 웃돌고 개인이 매일 700억~1000억원 순매수에 나섰지만 최근엔 가격이 크게 뛰는데도 거래대금과 순매수액 모두 반토막인 상태입니다. 이번엔 국내 가격도 김치프리미엄이 아니라 정말로 비싸서 오른 것이죠.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(  # Chat Completion API 호출\n",
    "    model = 'gpt-4.1-mini',\n",
    "    messages= [\n",
    "      {\"role\" : \"system\", \"content\" : \"너는 시사경제 전문가입니다. 주어진 뉴스기사의 핵심을 잘 요약/정리해주는 챗봇입니다. 사용자 입력값을 잘 읽고, 핵심내용 위주로 요약해주세요.\"},   \n",
    "      {\"role\" : \"user\", \"content\" : text} \n",
    "    ],\n",
    "    response_format= {'type' : \"text\"}, # 응답 형식\n",
    "    temperature= 0.2,                     # 모델의 랜덤성/다양성(낮으면 일관성, 높으면 창의적)\n",
    "    max_completion_tokens= 4096,        # 최대 출력 토큰\n",
    "    top_p= 1,                           # 누적확률 P까지의 후보를 샘플링(1이면 전체사용)\n",
    "\n",
    ")\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3f3f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_token_len = 741\n",
      "output_token_len = 386\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-4.1-mini'\n",
    "\n",
    "try:\n",
    "    enc = tiktoken.encoding_for_model(model)                # model에 매핑된 인코딩(토크나이저) 가져옴\n",
    "except:\n",
    "    print(f\"Warning : {model}을 찾을 수 없습니다.\")\n",
    "    enc = tiktoken.get_encoding('o200k_base')\n",
    "    \n",
    "input_token_len = len(enc.encode(text))                     # 입력(text)의 토큰 개수 계산\n",
    "output_token_len = len(enc.encode(output))                  # 출력(output)의 토큰 개수 계산\n",
    "print(f\"input_token_len = {input_token_len }\")\n",
    "print(f\"output_token_len = {output_token_len }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ff6cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_cost = 0.000648375\n",
      "output_cost = 0.002702\n",
      "total_cost = 0.003350375\n"
     ]
    }
   ],
   "source": [
    "# gpt 5.2 기준 input/output price\n",
    "input_price = 0.875\n",
    "output_price = 7\n",
    "\n",
    "input_cost = (input_price / 1_000_000) * input_token_len        # 1회 호출 기준 입력 비용\n",
    "output_cost = (output_price / 1_000_000) * output_token_len     # 1회 호출 기준 출력 비용\n",
    "total_cost = input_cost + output_cost                           # 1회 호출 기준 총 비용\n",
    "\n",
    "print(\"input_cost =\", input_cost)\n",
    "print(\"output_cost =\", output_cost)\n",
    "print(\"total_cost =\", total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "609c0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly_total_cost =  33503.75\n"
     ]
    }
   ],
   "source": [
    "num_service_call = 10_000_000\n",
    "monthly_total_cost = total_cost * num_service_call\n",
    "print(\"monthly_total_cost = \", monthly_total_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
