{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc18c5ae",
   "metadata": {},
   "source": [
    "# Model I/O \n",
    "\n",
    "![](https://d.pr/i/Wy5B5B+)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab7ee0",
   "metadata": {},
   "source": [
    "-q : 진행 로그를 일부 숨긴다  \n",
    "-qq : 대부분 숨긴다   \n",
    "-qqq : 성공 메시지까지 거의 다 숨김(문제가 생길경우만 로그 본다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\nlp\\nlp_venv\\lib\\site-packages (1.1.7)\n",
      "Requirement already satisfied: langchain in c:\\nlp\\nlp_venv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: torch in c:\\nlp\\nlp_venv\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain_openai) (1.2.8)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain_openai) (2.16.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.6.8)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\nlp\\nlp_venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\nlp\\nlp_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\nlp\\nlp_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\nlp\\nlp_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\nlp\\nlp_venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\nlp\\nlp_venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\nlp\\nlp_venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\nlp\\nlp_venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\nlp\\nlp_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\nlp\\nlp_venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\nlp\\nlp_venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2026.1.15)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
      "Requirement already satisfied: filelock in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\nlp\\nlp_venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp_venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\nlp\\nlp_venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\nlp\\nlp_venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_openai langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # .env 파일의 환경변수 로드\n",
    "import os                       # 환경변수 접근용\n",
    "\n",
    "load_dotenv()                   # 현재 위치의 .env를 읽어와 환경변수로 등록\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")  # .env의 openai_key 값을 OPENAI_API_KEY로 등록\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'                # LangSmith 트레이싱 활성화\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://api.smith.langchain.com'  # LangSmith API 엔드포인트 설정\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'                   # LangSmith 프로젝트명 설정\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")          # .env의 langsmith_key 값을 LANGSMITH_API_KEY로 등록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e50e3",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fce1192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nlp\\nlp_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'프랑스 여행을 계획하고 계시다면 다양한 매력을 가진 여행지가 많아요! 몇 가지 추천드릴게요:\\n\\n1. **파리 (Paris)**  \\n   - 에펠탑, 루브르 박물관, 노트르담 대성당, 몽마르트 언덕 등 세계적으로 유명한 명소가 가득합니다.  \\n   - 세느강 유람선도 인기 있는 활동이에요.\\n\\n2. **니스 (Nice)**  \\n   - 프랑스 리비에라의 중심 도시로, 아름다운 해변과 온화한 기후, 산책로인 프로메나드 데 장글레(Promenade des Anglais)가 유명해요.  \\n   - 예술가들의 도시이기도 합니다.\\n\\n3. **루아르 계곡 (Loire Valley)**  \\n   - 아름다운 성들이 즐비한 곳으로, 셰농소 성, 쉬농소 성, 앙보와즈 성 등 역사적인 건축물을 감상할 수 있어요.  \\n   - 와인 시음도 즐길 수 있는 지역입니다.\\n\\n4. **프로방스 (Provence)**  \\n   - 라벤더 밭, 고대 로마 유적, 전통 시장, 따뜻한 기후가 매력적인 지역이에요.  \\n   - 아비뇽, 엑상프로방스 등이 주요 도시입니다.\\n\\n5. **몽생미셸 (Mont Saint-Michel)**  \\n   - 조수 간만의 차로 인해 섬으로 변하는 독특한 수중 성곽 마을입니다.  \\n   - 중세 건축 양식과 자연경관이 인상적이에요.\\n\\n6. **보르도 (Bordeaux)**  \\n   - 세계적인 와인 산지로, 와인 투어와 함께 고풍스러운 도시 탐방을 할 수 있어요.  \\n   - 보르도 구시가지도 유네스코 세계문화유산에 등재되어 있습니다.\\n\\n이 중 관심 가는 지역이나 여행 스타일에 맞게 선택하시면 좋을 것 같아요! 더 구체적인 일정이나 테마가 필요하면 알려주세요.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI        # OpenAI 채팅 모델을 Langchain에서 쓰는 래퍼 클래스\n",
    "\n",
    "llm = ChatOpenAI(model= 'gpt-4.1-mini')        # llm 객체 생성\n",
    "llm.invoke('프랑스의 여행지 추천해줘.').content  # 사용자 입력로 모델 호출 -> AIMessage(content) 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccec5f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론입니다! 핀란드에서 꼭 가봐야 할 여행지 몇 곳을 추천해드릴게요:\\n\\n1. **헬싱키(Helsinki)**  \\n   핀란드의 수도로 현대적인 도시 분위기와 자연이 조화를 이루는 곳입니다.  \\n   - 세우라사리 야외 민속박물관(Seurasaari Open-Air Museum)  \\n   - 헬싱키 대성당(Helsinki Cathedral)  \\n   - 에스플라나디 공원(Esplanadi Park)  \\n   - 올루스섬(Otava Island)\\n\\n2. **라플란드(Lapland)**  \\n   북극권에 위치해 겨울에는 오로라를 볼 수 있고 산타클로스 마을(Santa Claus Village)이 유명합니다.  \\n   - 로바니에미(Rovaniemi) : 산타클로스 빌리지 방문  \\n   - 키루나(Kiruna) : 오로라 관측과 겨울 스포츠  \\n   - 사리셀카(Saariselkä) : 스키와 스노모빌 체험\\n\\n3. **투르쿠(Turku)**  \\n   핀란드에서 가장 오래된 도시로 중세 분위기를 느낄 수 있습니다.  \\n   - 투르쿠 성(Turku Castle)  \\n   - 투르쿠 대성당(Turku Cathedral)  \\n   - 아우란강을 따라 걷기 좋은 산책로\\n\\n4. **탐페레(Tampere)**  \\n   문화와 자연이 공존하는 도시로, 호수와 박물관이 많습니다.  \\n   - 비르타샤르키(Viikinsaari Island)  \\n   - 만세 동상(Mansen Statue)  \\n   - 핀란드 최초의 영화관 방문\\n\\n5. **사보(Savo) 지역**  \\n   호수와 숲이 아름다운 전통 마을들이 많아 핀란드 자연과 문화를 체험하기 좋습니다.  \\n   - 쿠오피오(Kuopio)  \\n   - 요엔수(Joensuu)\\n\\n핀란드는 사계절 모두 매력이 있지만 특히 겨울철에는 오로라, 크리스마스 축제, 겨울 스포츠가 유명하며, 여름에는 백야 현상을 체험하며 호숫가에서 캠핑과 하이킹하기 좋습니다.\\n\\n더 궁금한 점 있으면 알려주세요!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_chat_model  : 추상화된 객체 불러올때 쓰는 모델\n",
    "from langchain.chat_models import init_chat_model \n",
    "\n",
    "# OpenAi 모델 지정 + 파라미터 설정\n",
    "# llm = init_chat_model(model='gpt-4.1-mini', model_provider='openai', temperature = 1, top_p=1)\n",
    "llm = init_chat_model(model='openai:gpt-4.1-mini', temperature = 1, top_p=1)\n",
    "ai_message = llm.invoke('핀란드의 여행지 추천해줘.')# 프롬프트 호출 -> AIMessage 반환\n",
    "ai_message.content  # 본문 텍스트만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69ddeb",
   "metadata": {},
   "source": [
    "- 추상화된 채팅 LLM : init_chat_model()이 특정회사 (OpenAI / Anthropic / HuggingFace)의 클래스에 직접 묶이지 않게,  \n",
    "공통 인터페이스로 같은 방식(invoke, stream 등)으로 쓰게 만들어준다.    \n",
    "즉, init_chat_model()은 OpenAI 객체를 만드는 방식이 아니라, 여러 채팅 LLM들을 공통 규격으로 감싸서(추상화해서)  \n",
    "동일하게 쓸 수 있도록 만들어주는 팩토리 함수  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6460d25",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3474276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nTranslate this to French. I love prgramming~<|im_end|>\\n<|im_start|>assistant\\nJ'aime coder!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_chat_model  : 추상화된 객체 불러올때 쓰는 모델\n",
    "from langchain.chat_models import init_chat_model \n",
    "\n",
    "# OpenAi 모델 지정 + 파라미터 설정\n",
    "llm = init_chat_model(model='huggingface:Qwen/Qwen2.5-0.5B-Instruct', temperature = 1)\n",
    "ai_message = llm.invoke('Translate this to French. I love prgramming~')# 프롬프트 호출 -> AIMessage 반환\n",
    "ai_message.content  # 본문 텍스트만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab9936",
   "metadata": {},
   "source": [
    "### 모델 후보군 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375c86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== gpt-4.1-mini =====\n",
      "랭체인(LangChain)의 주요 장점은 다음과 같습니다:\n",
      "\n",
      "1. **언어 모델 통합 용이성**  \n",
      "   랭체인은 다양한 대형 언어 모델(예: OpenAI GPT, Cohere, Hugging Face 모델 등)과 쉽게 연동할 수 있는 인터페이스를 제공합니다. 덕분에 여러 모델을 한 프로젝트 내에서 손쉽게 활용할 수 있습니다.\n",
      "\n",
      "2. **모듈화된 아키텍처**  \n",
      "   프롬프트 템플릿, 체인(chain), 메모리, 에이전트(agent) 등 주요 컴포넌트를 모듈화해 재사용과 확장이 쉽습니다. 필요에 따라 각 부분만 교체하거나 조합하여 다양한 플로우를 구축할 수 있죠.\n",
      "\n",
      "3. **복잡한 워크플로우 구성 지원**  \n",
      "   랭체인은 단일 LLM 호출 이상의 복잡한 작업(예: 여러 단계 추론, 외부 API 연동, 조건 분기 등)을 체인으로 연결하여 자연스럽게 처리할 수 있게 해줍니다.\n",
      "\n",
      "4. **메모리 관리 기능**  \n",
      "   대화형 애플리케이션에서 문맥을 유지하기 위한 메모리 저장 및 불러오기 기능을 제공해, 보다 자연스럽고 일관된 대화 경험을 구현할 수 있습니다.\n",
      "\n",
      "5. **강력한 프롬프트 관리**  \n",
      "   프롬프트 템플릿을 체계적으로 관리하고, 변수 바인딩 및 조건부 로직 처리가 가능해 프롬프트 작성과 유지보수가 용이합니다.\n",
      "\n",
      "6. **커뮤니티와 생태계**  \n",
      "   활발한 오픈소스 커뮤니티와 다양한 플러그인, 연동 도구들이 지속적으로 발전 중이라 최신 AI 기술과 빠르게 접목할 수 있습니다.\n",
      "\n",
      "요약하면, 랭체인은 LLM 기반 애플리케이션 개발을 간편하게 만들고, 확장성과 유지보수성을 높여주는 프레임워크라고 할 수 있습니다.\n",
      "\n",
      "===== Qwen/Qwen2.5-0.5B-Instruct =====\n",
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "랭체인의 장점이 뭐야?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "랭크 인의 장점은 매우 다양하고 다양한데, 몇 가지를 설명해 드리겠습니다:\n",
      "\n",
      "1. 효율성: 랭크는 일반적으로 데이터가 가장 많이 쌓이고 있는 부분에 집중하여 최적화된 정보를 제공합니다. 이로 인해 데이터 처리 시간을 줄여 사용자에게 더快하게 알 수 있게 됩니다.\n",
      "\n",
      "2. 정확도: 랭크는 데이터베이스에서 실제 데이터와 일치하는 정보를 추출합니다. 이로 인해 정확한 정보를 제공함으로써 문제 해결에 큰 도움이 될 수 있습니다.\n",
      "\n",
      "3. 신뢰성: 랭크는 전체적인 데이터 상태를 보여주므로 사용자의 신뢰성을 증진시킵니다. 또한, 사용자가 특정 시점에 어떤 정보를 얻었는지 알 수 있도록 하여 사용자에게 정보를 제공할 수 있습니다.\n",
      "\n",
      "4. 유지보수: 랭크는 항상 업데이트되어 있어, 사용자의 기기나 환경이 변했거나, 데이터 베이스가 변경될 때마다 랭크를 업데이트할 수 있어, 데이터의 정\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 서로 다른 provider 모델들을 리스트로 준비\n",
    "models = [\n",
    "    init_chat_model('openai:gpt-4.1-mini'),\n",
    "    init_chat_model('huggingface:Qwen/Qwen2.5-0.5B-Instruct')\n",
    "]\n",
    "\n",
    "user_prompt = \"랭체인의 장점이 뭐야?\"   # 사용자의 질문\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    # model 객체에 model_name 속성이 있으면 model_name, 없으면 model_id를 사용\n",
    "    model_name = model.model_name if hasattr(model, 'model_name') else model.model_id \n",
    "    print(f\"===== {model_name} =====\")\n",
    "    ai_message = model.invoke(user_prompt)  # 모델 호출\n",
    "    print(ai_message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a996b0f",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4010e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"랭체인(LangChain)과 랭그래프(LangGraph)는 주로 자연어 처리와 인공지능 애플리케이션에서 활용되는 도구들이에요.\\n\\n1. **랭체인 (LangChain)**  \\n랭체인은 언어 모델(예: GPT)을 보다 효율적으로 활용하기 위한 프레임워크입니다. 복잡한 작업을 여러 단계로 나누고, 외부 데이터나 API, 도구와 연동해 언어 모델을 효과적으로 사용할 수 있도록 도와줘요. 예를 들어, 데이터베이스 검색, 문서 요약, 질문 답변 시스템 등을 쉽게 만들 수 있습니다.\\n\\n2. **랭그래프 (LangGraph)**  \\n랭그래프는 언어 모델과 관련된 작업 흐름이나 데이터 구조를 시각적으로 표현하고 관리할 수 있는 도구입니다. 자연어 처리 파이프라인이나 작업 간의 관계를 그래프 형태로 보여줘, 모델을 보다 직관적으로 이해하고 개선하는 데 도움을 줍니다.\\n\\n간단히 말해, 랭체인은 '언어 모델을 활용하는 개발 프레임워크'라면, 랭그래프는 '언어 모델 작업을 시각적으로 관리하는 도구'라고 볼 수 있습니다.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시스템/유저 메시지 리스트로 ChatModel을 호출해 응답을 출력\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')    # OpenAI 채팅 모델 초기화\n",
    "\n",
    "# (role, content) 튜플 형태의 대화 메시지\n",
    "messages = [\n",
    "    ('system', '당신은 친절한 챗봇입니다.'),            # 시스템 프롬프트\n",
    "    ('user', '랭체인/랭그래프를 간단히 설명해주세요.')   # 유저 메시지 \n",
    "]\n",
    "\n",
    "ai_message = llm.invoke(messages)\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee6127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'랭체인(LangChain)과 랭그래프(LangGraph)는 둘 다 언어 모델(예: GPT)을 효율적으로 활용하기 위한 도구입니다.\\n\\n1. 랭체인(LangChain)  \\n- 언어 모델을 여러 단계로 연결해 복잡한 작업을 수행할 수 있게 해주는 프레임워크입니다.  \\n- 데이터 연결, 프롬프트 설계, 메모리 관리, 외부 API 연동 등 다양한 기능을 제공합니다.  \\n- 예를 들어, 문서 요약 → 질문 생성 → 답변 생성 같은 작업을 순차적으로 처리할 때 유용합니다.\\n\\n2. 랭그래프(LangGraph)  \\n- 언어 모델을 활용한 작업 흐름을 그래프 형태로 시각화하고 관리할 수 있게 도와주는 도구입니다.  \\n- 각 노드가 언어 모델의 특정 작업(예: 질문 생성, 정보 추출 등)을 나타내고, 이들을 연결해 복잡한 파이프라인을 구현합니다.  \\n- 작업의 논리적 흐름과 데이터 이동을 한눈에 파악할 수 있어 개발과 디버깅에 편리합니다.\\n\\n요약하자면, 랭체인은 언어 모델 기반 작업을 쉽게 연결해주는 라이브러리이고, 랭그래프는 그런 연결 구조를 그래프로 시각화하고 관리하는 툴입니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Langchain의 메시지 객체(System/Human)로 LLM을 호출해 응답을 출력한다.\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage \n",
    "llm = init_chat_model('openai:gpt-4.1-mini')    # OpenAI 채팅 모델 초기화\n",
    "\n",
    "# (role, content) 튜플 형태의 대화 메시지\n",
    "messages = [\n",
    "    SystemMessage('당신은 친절한 챗봇입니다.'),            # 시스템 프롬프트\n",
    "     HumanMessage('랭체인/랭그래프를 간단히 설명해주세요.')   # 유저 메시지 \n",
    "]\n",
    "\n",
    "ai_message = llm.invoke(messages)\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f00175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['product'] input_types={} partial_variables={} template='{product}를 홍보하기 위한 참신한 문구를 작성해 줘.'\n",
      "전기차를 홍보하기 위한 참신한 문구를 작성해 줘.\n",
      "카메라를 홍보하기 위한 참신한 문구를 작성해 줘.\n",
      "==================답변====================\n",
      "물론입니다! 전기차를 홍보하기 위한 참신한 문구를 몇 가지 제안해 드릴게요.\n",
      "\n",
      "1. **\"미래를 달리는 힘, 전기차와 함께하세요.\"**  \n",
      "2. **\"지구를 생각하는 똑똑한 선택, 전기차로 시작하세요.\"**  \n",
      "3. **\"배출 제로, 즐거움 100%! 전기차와 새로운 여정을.\"**  \n",
      "4. **\"조용한 힘, 강력한 변화 – 전기차의 혁신을 경험하세요.\"**  \n",
      "5. **\"충전만 하면 달릴 준비 완료! 친환경 드라이빙의 시작.\"**  \n",
      "6. **\"환경도 살리고 주머니도 살리는 스마트한 이동, 전기차\"**  \n",
      "7. **\"전기로 움직이는 자유, 내일을 바꾸는 한 걸음.\"**\n",
      "\n",
      "필요하시면 특정 타깃층이나 캠페인 분위기에 맞게 더 맞춤형 문구도 만들어 드릴 수 있습니다!\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplat으로 프롬프트를 템플릿화해서 상품별 문구를 만들고 LLM을 생성\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 변수 {product}을 포함한 템플릿생성\n",
    "prompt = PromptTemplate.from_template('{product}를 홍보하기 위한 참신한 문구를 작성해 줘.')\n",
    "print(prompt)                               # 객체 정보\n",
    "print(prompt.format(product='전기차'))      # 변수를 채운 완성된 프롬프트 문자열\n",
    "print(prompt.format(product='카메라'))      # 변수를 채운 완성된 프롬프트 문자열\n",
    "\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "\n",
    "ai_message = llm.invoke(prompt.format(product='전기차'))\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['domain', 'question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['domain'], input_types={}, partial_variables={}, template='당신은 {domain}분야의 전문가입니다. 친절히 답해주세요'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question} 한글로 답해주세요.'), additional_kwargs={})]\n",
      "System: 당신은 IT분야의 전문가입니다. 친절히 답해주세요\n",
      "Human: langsmith 사용법 한글로 답해주세요.\n",
      "안녕하세요! Langsmith 사용법을 한글로 친절하게 설명드리겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## Langsmith란?\n",
      "Langsmith는 자연어 처리(NLP) 및 인공지능(AI) 모델 개발, 관리, 디버깅을 도와주는 플랫폼입니다. 주로 언어 모델을 효과적으로 다루고, 테스트하며, 성능을 분석하는 데 사용됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## Langsmith 기본 사용법\n",
      "\n",
      "1. **가입 및 로그인**\n",
      "   - Langsmith 웹사이트에 접속하여 회원가입을 합니다.\n",
      "   - 계정 생성 후 로그인합니다.\n",
      "\n",
      "2. **프로젝트 생성**\n",
      "   - 대시보드에서 새 프로젝트를 만듭니다.\n",
      "   - 프로젝트 이름과 설명을 입력하여 생성합니다.\n",
      "\n",
      "3. **데이터 업로드**\n",
      "   - 텍스트 데이터, 예제 문장, 학습 및 테스트용 데이터를 프로젝트에 업로드합니다.\n",
      "   - CSV, JSON 등의 포맷을 지원합니다.\n",
      "\n",
      "4. **모델 연결**\n",
      "   - Langsmith에서 제공하는 API를 사용하거나, 직접 학습한 AI 모델을 연결합니다.\n",
      "   - 모델을 연결하면 Langsmith 내에서 테스트가 가능해집니다.\n",
      "\n",
      "5. **모델 테스트 및 디버깅**\n",
      "   - 업로드한 데이터를 이용해 모델을 테스트 할 수 있습니다.\n",
      "   - 잘못된 응답, 오류 등을 쉽게 파악할 수 있도록 디버깅 도구가 제공됩니다.\n",
      "\n",
      "6. **성능 분석**\n",
      "   - Langsmith는 모델의 응답 시간, 정확도, 오류율 등 여러 성능 지표를 시각화해줍니다.\n",
      "   - 이를 통해 모델을 개선할 수 있는 부분을 발견합니다.\n",
      "\n",
      "7. **버전 관리 및 협업**\n",
      "   - 프로젝트의 여러 버전을 관리하면서 변경사항을 기록할 수 있습니다.\n",
      "   - 팀원과 프로젝트를 공유하여 함께 작업이 가능합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 팁\n",
      "\n",
      "- **API 문서 참고**: Langsmith에서 제공하는 API 문서를 자세히 읽으면 모델 연결과 테스트를 원활하게 할 수 있습니다.\n",
      "- **샘플 프로젝트 활용**: 처음 사용하신다면 샘플 프로젝트를 따라 해보시는 것을 추천합니다.\n",
      "- **커뮤니티 참여**: Langsmith 사용 관련 질문이나 팁을 공유하는 커뮤니티가 있으니 적극 참여하세요.\n",
      "\n",
      "---\n",
      "\n",
      "필요하신 더 구체적인 사용법이나 기능별 상세 설명이 있으면 말씀해 주세요! 친절히 안내해드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate으로 멀티턴(시스템/유저) 프롬프트를 템플릿화 하여 LLM 호출\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 여러 메시지(role, content)를 템플릿으로 구성\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system' , '당신은 {domain}분야의 전문가입니다. 친절히 답해주세요'),  \n",
    "    ('user' , '{question} 한글로 답해주세요.')    \n",
    "])\n",
    "\n",
    "print(chat_prompt)\n",
    "print(chat_prompt.format(domain = 'IT', question='langsmith 사용법'))   # 변수를 채운결과\n",
    "\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "\n",
    "ai_message = llm.invoke(chat_prompt.format(domain = 'IT', question='langsmith 사용법'))\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a1e11",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "객체의 출력에서 실제 값부분을 가져와 후 처리 작업을 담당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df5963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['달걀', '고구마', '대파', '쪽파']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CommaSeperatedListOutputParser : 콤마 구분 문자열 -> 리스트 변환 파서\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()   # 객체 생성\n",
    "model_output = \"달걀, 고구마, 대파, 쪽파\"    # 모델의 출력\n",
    "parser.parse(model_output)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "input_variables=['n', 'subject'] input_types={} partial_variables={'format_instruction': 'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'} template='{subject} 팀 {n}개를 작성해주세요. \\n(지시사항: {format_instruction})'\n",
      "프로야구 팀 5개를 작성해주세요. \n",
      "(지시사항: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`)\n"
     ]
    }
   ],
   "source": [
    "format_instruction = parser.get_format_instructions()               # 파서가 원하는 출력 형태 지시문 생성\n",
    "print(format_instruction)                                    \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    \n",
    "    # subject/n + 지시사항을 포함한 템플릿\n",
    "    template = \"{subject} 팀 {n}개를 작성해주세요. \\n(지시사항: {format_instruction})\" ,\n",
    "    input_variables = ['subject', 'n'],                             # 사용자가 채울 변수들\n",
    "    partial_variables = {'format_instruction' : format_instruction} # 고정으로 주입할 변수들 \n",
    "    \n",
    ")\n",
    "\n",
    "print(prompt)                                                       # 템플릿 구조\n",
    "print(prompt.format(subject = '프로야구', n=5))                      # 변수를 채운 최종 프롬프트 문자열 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='프로야구 팀 5개를 작성해주세요. \\n(지시사항: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`)'\n",
      "기아 타이거즈, 두산 베어스, LG 트윈스, 한화 이글스, 삼성 라이온즈\n",
      "['기아 타이거즈', '두산 베어스', 'LG 트윈스', '한화 이글스', '삼성 라이온즈']\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> LLM 호출 -> OutputParser로 리스트 변환\n",
    "input = prompt.invoke({'subject' : \"프로야구\", \"n\" : 5})        # 변수 (subject, n)을 넣어 프롬프트 메시지 생성\n",
    "print(input)\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')                    \n",
    "ai_message = llm.invoke(input)\n",
    "print(ai_message.content)\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "output = parser.invoke(ai_message)                              # LLM 응답을 콤마 기준으로 파싱 - 파이썬 리스트\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18708c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['두산 베어스', '기아 타이거즈', 'LG 트윈스', '삼성 라이온즈', '한화 이글스']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCEL(파이프)로 Prompt -> LLM -> OutputParser를 하나의 체인으로 연결해 실행\n",
    "chain = prompt | llm | parser                       # 체인: 프롬프트 -> 모델 -> 파서\n",
    "chain.invoke({'subject' : \"프로야구\", \"n\" : 5})       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f7fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "겨울 제철 과일에는 다음과 같은 것들이 있어요:\n",
      "\n",
      "1. 귤 - 한국 겨울을 대표하는 과일로, 달고 상큼해요.\n",
      "2. 감 - 겨울에 가장 맛있는 시기에 나며, 단맛이 강해요.\n",
      "3. 사과 - 겨울까지 저장된 사과가 맛있게 먹히고 품종에 따라 겨울까지도 즐길 수 있어요.\n",
      "4. 배 - 가을부터 겨울까지 먹을 수 있고, 아삭하고 시원한 맛이 특징이에요.\n",
      "5. 석류 - 겨울철에 많이 나오며, 새콤달콤한 맛과 건강에 좋은 영양소가 풍부해요.\n",
      "6. 키위 - 겨울철 비타민C 섭취에 좋은 과일로 인기 있어요.\n",
      "\n",
      "이 외에도 지역이나 기후에 따라 다양한 겨울 과일이 있으니 참고하세요!\n"
     ]
    }
   ],
   "source": [
    "# StrOutputParser : 모델 응답을 가공없이 문자열로 받아 출력\n",
    "from langchain_core.output_parsers import StrOutputParser   # AIMessages -> str(Content) 변환해주는 파서\n",
    "parser = StrOutputParser()                                  # 파서 객체 생성\n",
    "chain = llm | parser                                        # LLM 출력 -> 문자열로 파싱\n",
    "print(chain.invoke(\"겨울 제철 과일은 뭐가 있어?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd151c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return a JSON object.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'books': [{'title': '딥러닝 입문: 파이토치와 함께하는',\n",
       "   'author': '신경진',\n",
       "   'publisher': '한빛미디어',\n",
       "   'year': 2020,\n",
       "   'description': '파이토치 프레임워크를 사용하여 딥러닝의 기본 개념부터 실습까지 다루는 입문서.'},\n",
       "  {'title': '인공지능: 철학과 윤리',\n",
       "   'author': '김대식',\n",
       "   'publisher': '사이언스북스',\n",
       "   'year': 2019,\n",
       "   'description': '인공지능 기술의 철학적, 윤리적 문제를 심도 있게 탐구한 책.'},\n",
       "  {'title': '파이썬으로 배우는 머신러닝, 딥러닝 실전 개발 입문',\n",
       "   'author': '박해선',\n",
       "   'publisher': '위키북스',\n",
       "   'year': 2021,\n",
       "   'description': '파이썬 기반의 머신러닝과 딥러닝 기술을 실제 예제로 배울 수 있는 실무서.'},\n",
       "  {'title': '인공지능 개론',\n",
       "   'author': '이광형',\n",
       "   'publisher': '교보문고 출판부',\n",
       "   'year': 2018,\n",
       "   'description': '인공지능의 기본 원리와 알고리즘을 체계적으로 설명하는 대학 교재 수준의 책.'},\n",
       "  {'title': '자연어 처리와 딥러닝',\n",
       "   'author': '조성배',\n",
       "   'publisher': '한빛아카데미',\n",
       "   'year': 2022,\n",
       "   'description': '자연어 처리 분야의 딥러닝 기법과 최신 연구 동향을 다루는 전문서.'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JsonOutputParser : 모델의 JSON 문자열 응답을 파이썬 객체 dict/list로 변환(파싱)하는 파서\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "format_instruction = parser.get_format_instructions()           # 모델에게 JSON 으로 답하라고 지시하는 문구 생성\n",
    "print(format_instruction)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    # subject/n + JSON 지시사항 포함\n",
    "    template = '{subject} 분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.\\n(지시사항 : {format_instruction})',\n",
    "    input_variables = [\"subject\", \"n\"],                                 # 사용자가 채울 변수들\n",
    "    partial_variables = {\"format_instruction\": format_instruction}      # 고정으로 주입할 변수 \n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser                                           # 체인 : 프롬프트 -> LLM -> JSON 파서\n",
    "result = chain.invoke({'subject' : '인공지능', 'n' : 5})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e49ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Book\": {\"properties\": {\"title\": {\"title\": \"Title\", \"type\": \"string\"}, \"author\": {\"title\": \"Author\", \"type\": \"string\"}, \"publisher\": {\"title\": \"Publisher\", \"type\": \"string\"}, \"year\": {\"default\": null, \"title\": \"Year\", \"type\": \"integer\"}, \"description\": {\"title\": \"Description\", \"type\": \"string\"}}, \"required\": [\"title\", \"author\", \"publisher\", \"description\"], \"title\": \"Book\", \"type\": \"object\"}}, \"properties\": {\"books\": {\"items\": {\"$ref\": \"#/$defs/Book\"}, \"title\": \"Books\", \"type\": \"array\"}}, \"required\": [\"books\"]}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BookList(books=[Book(title='인공지능 개론', author='이광성', publisher='한빛아카데미', year=2020, description='인공지능의 기본 개념과 최신 동향을 폭넓게 다룬 입문서로, 인공지능의 원리와 응용을 이해하는 데 도움을 줍니다.'), Book(title='파이썬으로 배우는 인공지능', author='박해선', publisher='이지스퍼블리싱', year=2019, description='파이썬을 활용하여 인공지능 알고리즘을 직접 구현하며 학습할 수 있도록 구성된 실습 중심의 책입니다.'), Book(title='딥러닝 입문', author='김성훈', publisher='한빛미디어', year=2018, description='딥러닝의 기본 개념과 신경망 구조를 쉽게 설명하고 다양한 예제와 함께 실습할 수 있는 입문서입니다.'), Book(title='인공지능: 기계학습과 딥러닝', author='조규태', publisher='홍릉과학출판사', year=2021, description='기계학습과 딥러닝의 이론부터 실제 응용까지 체계적으로 다룬 심화 학습서입니다.'), Book(title='머신러닝 교과서 with 파이썬, 사이킷런, 텐서플로', author='세바스찬 라시카, 박해선 (역자)', publisher='한빛미디어', year=2017, description='파이썬과 대표적인 라이브러리를 사용하여 머신러닝 개념과 알고리즘을 체계적으로 설명한 실무 지침서입니다.')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PydanticOutputParser : 스키마(형식)을 강제해서 구조화된 책 목록을 받는 코드\n",
    "from pydantic import BaseModel                                      # 데이터 스키마(모델) 정의용\n",
    "from langchain_core.output_parsers import PydanticOutputParser      # LLM 출력 -> Pydantic 객체로 검증 / 변환\n",
    "from typing import List                                             # 리스트 타입 힌트용\n",
    "\n",
    "\n",
    "# 책 1권마다의 스키마 정의\n",
    "class Book(BaseModel):                                             \n",
    "    title : str\n",
    "    author : str\n",
    "    publisher : str\n",
    "    year : int = None   # 출간연도(없어도 상관없음)\n",
    "    description : str  \n",
    "    \n",
    "\n",
    "# 책 여려권을 담는 스키마 정의\n",
    "class BookList(BaseModel):\n",
    "    books : List[Book]\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=BookList)             # 출력이 BookList 형태가 되도록 파서 생성\n",
    "format_instruction = parser.get_format_instructions()               # 스키마대로 출력하도록 만드는 지시문\n",
    "print(format_instruction)                                            \n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    \n",
    "    # subject/n + JSON 지시사항 포함\n",
    "    template = '{subject} 분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.\\n(지시사항 : {format_instruction})',\n",
    "    input_variables = [\"subject\", \"n\"],                                 # 사용자가 채울 변수들\n",
    "    partial_variables = {\"format_instruction\": format_instruction}      # 고정으로 주입할 변수 \n",
    "    \n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser                                           # 체인 : 프롬프트 -> LLM -> Pydantic 파서\n",
    "result = chain.invoke({'subject' : '인공지능', 'n' : 5})                # 파싱/검증된 BookList 객체 반환\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbee9da",
   "metadata": {},
   "source": [
    "- Book / BookList는 pydantic.BaseModel을 상속한 스키마(데이터 모델)이다.  \n",
    "- result는 그 스키마로 만들어진 Pytdantic 객체(인스턴스)  \n",
    "\n",
    "- 사용하면  \n",
    "    - 필드가 있는지 검사  \n",
    "    - 타입 검사/변환  \n",
    "    - 구조가 맞는지 검사  \n",
    "\n",
    "- dictionary와 차이점\n",
    "    - dict : 아무키나 들어갈수 있고, 타입도 상관없다.\n",
    "    - Pydatic 객체 : 정해진 키/타입만 허용. 틀리면 잡아준다(검증)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd6e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BookList(books=[Book(title='인공지능: 현대적 접근', author='스튜어트 러셀, 피터 노빅', publisher='에이콘출판', year=2020, description='인공지능 분야의 대표적인 교재로, 기초부터 최신 기술까지 폭넓게 다루는 책입니다.'), Book(title='딥러닝 입문', author='사이토 고키', publisher='한빛미디어', year=2018, description='딥러닝의 기초 원리와 구현 방법을 한국어로 쉽게 설명한 입문서입니다.'), Book(title='파이썬으로 배우는 머신러닝, 딥러닝 실전 개발 입문', author='박해선', publisher='위키북스', year=2019, description='파이썬을 활용한 머신러닝과 딥러닝의 실전 예제를 다룹니다.'), Book(title='머신러닝 교과서 with 파이썬, 사이킷런, 텐서플로', author='세바스찬 라쉬카, 바히드 미자리', publisher='한빛미디어', year=2019, description='머신러닝 이론부터 파이썬 라이브러리 활용까지 상세히 설명하는 교과서적 책입니다.'), Book(title='인공지능 기초와 응용', author='홍성철', publisher='생능출판사', year=2021, description='인공지능의 기초 개념과 다양한 응용 사례를 폭넓게 다룬 한국어 교재입니다.')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with_structured_output() : Pydantic 스키마를 받아 구조화된 결과를 바로 받는다.\n",
    "prompt = PromptTemplate( \n",
    "    # subject/n + JSON 지시사항 포함\n",
    "    template = '{subject} 분야의 유명한 한국어 책 {n}권 정보를 제공해주세요.)',\n",
    "    input_variables = [\"subject\", \"n\"],                                 # 사용자가 채울 변수들      \n",
    ")\n",
    "\n",
    "chain = prompt | llm.with_structured_output(BookList)                  # LLM의 출력이 BookList 스키마를 따르도록 래핑\n",
    "result = chain.invoke({'subject' : '인공지능', 'n' : 5})                # 파싱/검증된 BookList 객체 반환\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
