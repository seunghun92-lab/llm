{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ea0b46",
   "metadata": {},
   "source": [
    "# AI Wine Sommelier RAG\n",
    "\n",
    "## Wine Review Indexing\n",
    "\n",
    "https://www.kaggle.com/datasets/christopheiv/winemagdata130k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de7b666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq langchain langchain-openai langchain-pinecone langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141aaec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\nlp\\nlp_venv\\Lib\\site-packages (26.0.1)\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d024c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # .env 파일의 환경변수 로드\n",
    "import os                       # 환경변수 접근용\n",
    "\n",
    "load_dotenv()                                                         # 현재 위치의 .env를 읽어와 환경변수로 등록\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")                # .env의 openai_key 값을 OPENAI_API_KEY로 등록\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'                              # LangSmith 트레이싱 활성화\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://api.smith.langchain.com'  # LangSmith API 엔드포인트 설정\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'                   # LangSmith 프로젝트명 설정\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")          # .env의 langsmith_key 값을 LANGSMITH_API_KEY로 등록\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"tavily_key\")                 \n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"pinecone_key\")                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e9314",
   "metadata": {},
   "source": [
    "## Pinecone 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9bdec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로드\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain은 LLM 기반 애플리케이션을 쉽게 만들 수 있는 프레임워크입니다.\", metadata={\"source\": \"https://langchain.com/docs\", \"author\": \"alice\", \"page\": 1}),\n",
    "    Document(page_content=\"ChromaDB는 오픈소스 벡터 데이터베이스입니다.\", metadata={\"source\": \"https://chromadb.org/intro\", \"license\": \"MIT\", \"date\": \"2024-07-01\"}),\n",
    "    Document(page_content=\"파이썬으로 AI 서비스를 개발할 수 있습니다.\", metadata={\"source\": \"https://pythonai.co.kr\", \"editor\": \"kim\", \"page\": 7}),\n",
    "    Document(page_content=\"LLM은 자연어 처리를 위한 대형 언어 모델을 의미합니다.\", metadata={\"source\": \"https://llmwiki.com/info\", \"author\": \"bob\", \"version\": \"v1.1\"}),\n",
    "    Document(page_content=\"RAG는 검색과 생성의 결합 방식을 제공합니다.\", metadata={\"source\": \"https://rag-search.io\", \"reviewer\": \"lee\", \"section\": \"summary\"}),\n",
    "    Document(page_content=\"벡터 데이터베이스는 임베딩된 데이터를 효율적으로 검색할 수 있습니다.\", metadata={\"source\": \"https://vectorbase.net\", \"author\": \"jin\", \"topic\": \"vector\"}),\n",
    "    Document(page_content=\"LangChain을 이용하면 다양한 AI 파이프라인을 구축할 수 있습니다.\", metadata={\"source\": \"https://langchain.com/blog\", \"editor\": \"sarah\", \"date\": \"2024-06-30\"}),\n",
    "    Document(page_content=\"OpenAI의 GPT 모델은 텍스트 생성에 특화되어 있습니다.\", metadata={\"source\": \"https://openai.com/gpt\", \"lang\": \"ko\", \"page\": 5}),\n",
    "    Document(page_content=\"파이썬은 AI 및 데이터 분석 분야에서 널리 사용되는 언어입니다.\", metadata={\"source\": \"https://python.org/usecases\", \"author\": \"chun\", \"updated\": \"2024-05\"}),\n",
    "    Document(page_content=\"Streamlit은 파이썬으로 대시보드를 쉽게 만들 수 있는 프레임워크입니다.\", metadata={\"source\": \"https://streamlit.io/start\", \"editor\": \"park\", \"date\": \"2024-04-28\"}),\n",
    "    Document(page_content=\"Dense Retrieval은 임베딩 벡터를 이용한 검색 방식을 의미합니다.\", metadata={\"source\": \"https://retrieval.ai/dense\", \"type\": \"tech\", \"page\": 3}),\n",
    "    Document(page_content=\"Pandas 라이브러리는 데이터 분석에 자주 사용됩니다.\", metadata={\"source\": \"https://pandas.pydata.org/about\", \"maintainer\": \"koh\", \"section\": \"intro\"}),\n",
    "    Document(page_content=\"메타데이터 필터링은 검색 결과의 품질을 높여줍니다.\", metadata={\"source\": \"https://search.com/metadata\", \"author\": \"seo\", \"feature\": \"filter\"}),\n",
    "    Document(page_content=\"SelfQueryRetriever는 자연어 쿼리를 임베딩 쿼리로 변환해줍니다.\", metadata={\"source\": \"https://selfquery.ai\", \"editor\": \"min\", \"date\": \"2024-05-12\"}),\n",
    "    Document(page_content=\"프롬프트 엔지니어링은 LLM의 성능을 극대화하는 방법입니다.\", metadata={\"source\": \"https://prompting.dev/guide\", \"author\": \"yang\", \"topic\": \"prompt\"}),\n",
    "    Document(page_content=\"HyDE 기법은 하이브리드 검색에 사용됩니다.\", metadata={\"source\": \"https://hyde-tech.com\", \"reviewer\": \"kang\", \"version\": \"2024.1\"}),\n",
    "    Document(page_content=\"CoT는 복잡한 문제를 단계적으로 해결하는 프롬프트 기법입니다.\", metadata={\"source\": \"https://cotprompt.org\", \"editor\": \"jung\", \"date\": \"2023-12-01\"}),\n",
    "    Document(page_content=\"문서 임베딩은 텍스트를 고차원 벡터로 변환하는 과정입니다.\", metadata={\"source\": \"https://embedding.ai/intro\", \"section\": \"embedding\", \"author\": \"song\"}),\n",
    "    Document(page_content=\"CrewAI는 멀티 에이전트 시스템 구현을 돕는 툴입니다.\", metadata={\"source\": \"https://crew.ai/docs\", \"lang\": \"ko\", \"page\": 9}),\n",
    "    Document(page_content=\"Fine-tuning은 사전학습 모델을 특정 도메인에 맞게 재학습시키는 과정입니다.\", metadata={\"source\": \"https://finetune.ai/guide\", \"editor\": \"jeon\", \"date\": \"2024-01-30\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff71e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nlp\\nlp_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings           # 문서 텍스트를 임베딩 벡터로 변환\n",
    "from langchain_pinecone import PineconeVectorStore      # Pinecone 인덱스에 임베딩/문서를 저장하는 벡터스토어\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "\n",
    "# 문서 -> 임베딩 -> Pinecone 업로드\n",
    "vector_store = PineconeVectorStore.from_documents(\n",
    "    documents,                      # 업로드할 Document(청크) 리스트\n",
    "    embeddings,                     # 임베딩 모델\n",
    "    index_name = 'pinecone-first'   # Pinecone 인덱스 이름\n",
    "      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fecb71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b1990659-cd96-443a-adf3-42f1a98bc25e', metadata={'author': 'jin', 'source': 'https://vectorbase.net', 'topic': 'vector'}, page_content='벡터 데이터베이스는 임베딩된 데이터를 효율적으로 검색할 수 있습니다.'),\n",
       " Document(id='e6b3f38f-3091-45b4-a883-5633255aef66', metadata={'date': '2024-07-01', 'license': 'MIT', 'source': 'https://chromadb.org/intro'}, page_content='ChromaDB는 오픈소스 벡터 데이터베이스입니다.'),\n",
       " Document(id='1195abb8-b253-4e1f-8628-aeaa876ace80', metadata={'page': 3.0, 'source': 'https://retrieval.ai/dense', 'type': 'tech'}, page_content='Dense Retrieval은 임베딩 벡터를 이용한 검색 방식을 의미합니다.'),\n",
       " Document(id='8042bc2c-44e2-44b5-8597-c5e95766a71e', metadata={'author': 'song', 'section': 'embedding', 'source': 'https://embedding.ai/intro'}, page_content='문서 임베딩은 텍스트를 고차원 벡터로 변환하는 과정입니다.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질의를 임베딩 한 뒤 가장 유사한 Document 리스트 반환\n",
    "retrievals = vector_store.similarity_search('벡터 데이터베이스란?')\n",
    "retrievals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf6a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChromaDB는 오픈소스 벡터 데이터베이스입니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievals[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b582dd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b1990659-cd96-443a-adf3-42f1a98bc25e', metadata={'author': 'jin', 'source': 'https://vectorbase.net', 'topic': 'vector'}, page_content='벡터 데이터베이스는 임베딩된 데이터를 효율적으로 검색할 수 있습니다.'),\n",
       " Document(id='ca4d3883-883e-4b66-9051-4f8213a556ba', metadata={'author': 'jin', 'source': 'https://vectorbase.net', 'topic': 'vector'}, page_content='벡터 데이터베이스는 임베딩된 데이터를 효율적으로 검색할 수 있습니다.'),\n",
       " Document(id='e6b3f38f-3091-45b4-a883-5633255aef66', metadata={'date': '2024-07-01', 'license': 'MIT', 'source': 'https://chromadb.org/intro'}, page_content='ChromaDB는 오픈소스 벡터 데이터베이스입니다.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PineconeVectorStore를 Retriever로 변환해 Top-k 검색\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = 'similarity',\n",
    "    search_kwargs =  {'k' : 3}\n",
    ")\n",
    "\n",
    "retriever.invoke('벡터 데이터베이스란?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51626bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\nlp\\nlp_venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "129971\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader          # CSV의 각 행(row)를 하나의 Document 객체로 변환하는 로더\n",
    "\n",
    "loader = CSVLoader('winemag-data-130k-v2.csv', encoding='utf-8')    # CSV 경로/인코딩 지정\n",
    "docs = loader.load()                                                # CSV를 Document 리스트로 로드(행 단우ㅏ)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94bf32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "docs = docs[:30000]\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a3296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <class 'langchain_core.documents.base.Document'>\n",
      "{'source': 'winemag-data-130k-v2.csv', 'row': 0}\n",
      ": 0\n",
      "country: Italy\n",
      "description: Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
      "designation: Vulkà Bianco\n",
      "points: 87\n",
      "price: \n",
      "province: Sicily & Sardinia\n",
      "region_1: Etna\n",
      "region_2: \n",
      "taster_name: Kerin O’Keefe\n",
      "taster_twitter_handle: @kerinokeefe\n",
      "title: Nicosia 2013 Vulkà Bianco  (Etna)\n",
      "variety: White Blend\n",
      "winery: Nicosia\n",
      "\n",
      "2 : <class 'langchain_core.documents.base.Document'>\n",
      "{'source': 'winemag-data-130k-v2.csv', 'row': 1}\n",
      ": 1\n",
      "country: Portugal\n",
      "description: This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red berry fruits and freshened with acidity. It's  already drinkable, although it will certainly be better from 2016.\n",
      "designation: Avidagos\n",
      "points: 87\n",
      "price: 15.0\n",
      "province: Douro\n",
      "region_1: \n",
      "region_2: \n",
      "taster_name: Roger Voss\n",
      "taster_twitter_handle: @vossroger\n",
      "title: Quinta dos Avidagos 2011 Avidagos Red (Douro)\n",
      "variety: Portuguese Red\n",
      "winery: Quinta dos Avidagos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV 로더 결과 확인\n",
    "for i, doc in enumerate(docs[:2], 1):   # Document 중 앞 2개 확인(index 1부터 시작)\n",
    "    print(f\"{i} : {type(doc)}\")         \n",
    "    print(f\"{doc.metadata}\")\n",
    "    print(f\"{doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e36e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 ~ 300\n",
      "index: 300 ~ 600\n",
      "index: 600 ~ 900\n",
      "index: 900 ~ 1200\n",
      "index: 1200 ~ 1500\n",
      "index: 1500 ~ 1800\n",
      "index: 1800 ~ 2100\n",
      "index: 2100 ~ 2400\n",
      "index: 2400 ~ 2700\n",
      "index: 2700 ~ 3000\n",
      "index: 3000 ~ 3300\n",
      "index: 3300 ~ 3600\n",
      "index: 3600 ~ 3900\n",
      "index: 3900 ~ 4200\n",
      "index: 4200 ~ 4500\n",
      "index: 4500 ~ 4800\n",
      "index: 4800 ~ 5100\n",
      "index: 5100 ~ 5400\n",
      "index: 5400 ~ 5700\n",
      "index: 5700 ~ 6000\n",
      "index: 6000 ~ 6300\n",
      "index: 6300 ~ 6600\n",
      "index: 6600 ~ 6900\n",
      "index: 6900 ~ 7200\n",
      "index: 7200 ~ 7500\n",
      "index: 7500 ~ 7800\n",
      "index: 7800 ~ 8100\n",
      "index: 8100 ~ 8400\n",
      "index: 8400 ~ 8700\n",
      "index: 8700 ~ 9000\n",
      "index: 9000 ~ 9300\n",
      "index: 9300 ~ 9600\n",
      "index: 9600 ~ 9900\n",
      "index: 9900 ~ 10200\n",
      "index: 10200 ~ 10500\n",
      "index: 10500 ~ 10800\n",
      "index: 10800 ~ 11100\n",
      "index: 11100 ~ 11400\n",
      "index: 11400 ~ 11700\n",
      "index: 11700 ~ 12000\n",
      "index: 12000 ~ 12300\n",
      "index: 12300 ~ 12600\n",
      "index: 12600 ~ 12900\n",
      "index: 12900 ~ 13200\n",
      "index: 13200 ~ 13500\n",
      "index: 13500 ~ 13800\n",
      "index: 13800 ~ 14100\n",
      "index: 14100 ~ 14400\n",
      "index: 14400 ~ 14700\n",
      "index: 14700 ~ 15000\n",
      "index: 15000 ~ 15300\n",
      "index: 15300 ~ 15600\n",
      "index: 15600 ~ 15900\n",
      "index: 15900 ~ 16200\n",
      "index: 16200 ~ 16500\n",
      "index: 16500 ~ 16800\n",
      "index: 16800 ~ 17100\n",
      "index: 17100 ~ 17400\n",
      "index: 17400 ~ 17700\n",
      "index: 17700 ~ 18000\n",
      "index: 18000 ~ 18300\n",
      "index: 18300 ~ 18600\n",
      "index: 18600 ~ 18900\n",
      "index: 18900 ~ 19200\n",
      "index: 19200 ~ 19500\n",
      "index: 19500 ~ 19800\n",
      "index: 19800 ~ 20100\n",
      "index: 20100 ~ 20400\n",
      "index: 20400 ~ 20700\n",
      "index: 20700 ~ 21000\n",
      "index: 21000 ~ 21300\n",
      "index: 21300 ~ 21600\n",
      "index: 21600 ~ 21900\n",
      "index: 21900 ~ 22200\n",
      "index: 22200 ~ 22500\n",
      "index: 22500 ~ 22800\n",
      "index: 22800 ~ 23100\n",
      "index: 23100 ~ 23400\n",
      "index: 23400 ~ 23700\n",
      "index: 23700 ~ 24000\n",
      "index: 24000 ~ 24300\n",
      "index: 24300 ~ 24600\n",
      "index: 24600 ~ 24900\n",
      "index: 24900 ~ 25200\n",
      "index: 25200 ~ 25500\n",
      "index: 25500 ~ 25800\n",
      "index: 25800 ~ 26100\n",
      "index: 26100 ~ 26400\n",
      "index: 26400 ~ 26700\n",
      "index: 26700 ~ 27000\n",
      "index: 27000 ~ 27300\n",
      "index: 27300 ~ 27600\n",
      "index: 27600 ~ 27900\n",
      "index: 27900 ~ 28200\n",
      "index: 28200 ~ 28500\n",
      "index: 28500 ~ 28800\n",
      "index: 28800 ~ 29100\n",
      "index: 29100 ~ 29400\n",
      "index: 29400 ~ 29700\n",
      "index: 29700 ~ 30000\n"
     ]
    }
   ],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    index_name= \"winemag-data-130k-v2\", # 업로드 대상 인덱스 이름\n",
    "    embedding = embeddings              # 임베딩 모델\n",
    ")\n",
    "\n",
    "batch_size = 300                             # 한 번에 업로드할 Document 개수\n",
    "\n",
    "for i in range(0, len(docs), batch_size):       # 전체 docs를 batch_size 단위로 순회\n",
    "    batch_data = docs[i: i + batch_size]\n",
    "    vector_store.add_documents(batch_data)      # 배치 Document들을 임베딩 후 Pinecone 업로드\n",
    "    print(f\"index: {i} ~ {i+batch_size}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927298a",
   "metadata": {},
   "source": [
    "## Retrieval & Generation\n",
    "1. 텍스트/이미지 입력으로 요리에 설명 chain\n",
    "2. 요리설명텍스트 벡터db조회 chain\n",
    "3. 요리설명/리뷰검색을 가지고 와인추천 응답 chain\n",
    "\n",
    "\n",
    "### 요리설명 chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d2b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 첫 번째 요리인 족발은 은은한 간장과 향신료가 스며든 쫄깃한 육질이 혀끝에서 부드럽게 녹으며 고소하면서도 감칠맛이 깊게 전해집니다.\n",
      "\n",
      "2. 두 번째 요리인 닭발구이는 매콤한 고추장 소스가 강렬하게 입안을 자극하며, 쫄깃한 식감과 함께 불맛이 어우러져 중독성 있는 풍미를 선사합니다.\n",
      "\n",
      "3. 세 번째 요리인 제육볶음은 고추장의 매콤함과 달큰한 양념이 조화를 이루고, 얇게 썬 돼지고기가 부드럽게 씹히며 달큰하고 짭짤한 맛이 입안 가득 퍼집니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate  # 프롬프트 템플릿 관련 클래스\n",
    "from langchain.chat_models import init_chat_model  # OpenAI 채팅 모델을 LangChain에서 쓰기 위한 함수\n",
    "from langchain_core.output_parsers import StrOutputParser  # LLM 출력에서 문자열만 추출하는 파서\n",
    "from langchain_core.runnables import RunnableLambda  # 일반 함수를 Runnable로 감싸주는 도구\n",
    "\n",
    "def describe_dish_flavor(query : dict):  # 사용자 입력(query)을 받아 체인을 생성하는 함수\n",
    "    prompt = ChatPromptTemplate.from_messages([  # system / human 메시지로 프롬프트 구성\n",
    "        ('system', ''' ... '''),  # LLM의 페르소나, 작성 규칙, 예시 등을 정의하는 시스템 메시지\n",
    "        ('human', '사용자가 제공한 이미지의 요리명과 풍미를 잘 묘사해주세요.')  # 기본 사용자 요청 메시지\n",
    "    ])    \n",
    "    \n",
    "    temp = []  # 이미지와 텍스트를 담기 위한 임시 리스트\n",
    "\n",
    "    if query.get('image_urls'):  # query의 이미지 URL 키가 있는 경우\n",
    "        temp += [{\"image_url\" : image_url} for image_url in query.get('image_urls')]  # temp에 이미지 정보 추가\n",
    "\n",
    "    if query.get('text'):  # 텍스트 입력이 있다면\n",
    "        temp += [{\"text\" : query.get('text')}]  # temp에 텍스트 정보 추가\n",
    "        \n",
    "    #위에서 만든 멀티모달 블록(temp)를 human 메시지로 프롬프트에 추가\n",
    "    prompt += HumanMessagePromptTemplate.from_template(temp)  \n",
    "    \n",
    "        \n",
    "    llm = init_chat_model('openai:gpt-4.1-mini')  # GPT-4.1-mini 모델 초기화\n",
    "    output_parser = StrOutputParser()  # 문자열 출력 파서 생성\n",
    "    \n",
    "    chain = prompt | llm | output_parser  # 프롬프트 → LLM → 파서 순서로 체인 구성\n",
    "    \n",
    "    return chain \n",
    "\n",
    "dish_flavor_chain = RunnableLambda(describe_dish_flavor)  # 입력을 받아 체인을 만들어 실행하는 Runnable\n",
    "\n",
    "response = dish_flavor_chain.invoke({  # Runnable 실행 (.invoke 필수)\n",
    "    'text' : '',\n",
    "    'image_urls' : [\n",
    "        \"https://search.pstatic.net/common/?src=...\",\n",
    "        \"https://search.pstatic.net/common/?src=...\",\n",
    "        \"https://search.pstatic.net/common/?src=...\"\n",
    "    ]  # 요리 사진 URL 여러장\n",
    "})\n",
    "\n",
    "print(response)  # 결과 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f05945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
