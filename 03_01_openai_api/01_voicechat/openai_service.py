# SST (Speech -> Text) + GPT ì‘ë‹µ + TTS (Text -> Speech) íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ëª¨ìŒ
# SST : ì‚¬ìš©ìì˜ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper ëª¨ë¸ ë“±)
# LLM(GPT) : ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ ìƒì„±
# TTS : ìƒì„±ëœ ë‹µë³€ì„ ë‹¤ì‹œ ìŒì„± íŒŒì¼ë¡œ ë³€í™˜

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
import base64                       # mp3 ì´ì§„ë°ì´í„°ë¥¼ base64 ë¬¸ìì—´ë¡œ ë°ì´í„° ì¸ì½”ë”© (ìƒì„±ëœ ìŒì„±(ì´ì§„ë°ì´í„°)ë¥¼ ì›¹ì´ë‚˜ ì•±ì—ì„œ ì£¼ê³  ë°›ê¸° ìœ„í•´ ë¬¸ìì—´ í˜•íƒœë¡œ ë°”ê¾¸ëŠ” ê¸°ìˆ )
from dotenv import load_dotenv      # .env í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (APIí‚¤ë¥¼ ê°€ì ¸ì˜´. os.environ)
from openai import OpenAI           # OpenAI í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
import os                           # ìš´ì˜

load_dotenv()       # .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ë³€ìˆ˜ ë“±ë¡. 
OPENAI_API_KEY = os.environ['openai_key']       # .env ì— ì €ì¥ëœ openai_key ê°’ì„ ê°€ì ¸ì˜´
client = OpenAI(api_key= OPENAI_API_KEY)        # OpenAI í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„± (í‚¤ ì§ì ‘ ì£¼ì…)


# ì˜¤ë””ì˜¤ ê°ì²´ë¥¼ Whisperë¡œ SSTí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ìŒì„±ì„ ê¸€ìë¡œ ë°”ê¾¸ê¸°)
def stt(audio):
    output_filepath = 'input.mp3'                  # input.mp3(ì„ì‹œ ì €ì¥ìš© íŒŒì¼) íŒŒì¼ì— ì„ì‹œ ì €ì¥í•¨.
    audio.export(output_filepath, format = 'mp3')   # ì˜¤ë””ì˜¤ ê°ì²´ë¥¼ mp3 íŒŒì¼ë¡œ ì €ì¥


    with open(output_filepath, 'rb') as f:          # ì €ì¥ëœ íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ì—°ë‹¤.
        # STT ìš”ì²­ (ìŒì„± -> TXT) 
        transcription = client.audio.transcriptions.create(
            model = 'whisper-1',
            file = f
        )
    
    os.remove(output_filepath)         # ì„ì‹œë¡œ ë§Œë“  íŒŒì¼(input.mp3)ì„ ì‚­ì œ (.mp4ëŠ” ì˜ìƒ ë“± ì—¬ëŸ¬ê°€ì§€ ê°€ëŠ¥.? ë­ê°€ ë“¤ì–´ì˜¤ë“  mp3í˜•íƒœë¡œ)

    return transcription.text       # STT ê²°ê³¼ í…ìŠ¤íŠ¸ ë°˜í™˜

# ë©”ì„¸ì§€ íˆìŠ¤í† ë¦¬ì™€ ëª¨ë¸ì„ ë°›ì•„ í•´ë‹¹ GPTë¡œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì§ˆë¬¸ì„ í•˜ê³  ë‹µë³€ ë°›ê¸°)
def ask_gpt(messages, model):
    # GPT ì±„íŒ… ì‘ë‹µ ë°˜í™˜
    return client.chat.completions.create(
        model = model,
        messages = messages,
        temperature= 1,                 # ì°½ì˜ì„± (ìƒì„± ë‹¤ì–‘ì„±) : ë†’ì„ ìˆ˜ë¡ ëœë¤ì„±(ì°½ì˜ì„±)
        top_p= 1,                       # nucleus sampling(1ì´ë©´ ì œí•œ ì—†ìŒ)
        max_completion_tokens= 4096     # ìƒì„± í† í° ìµœëŒ€ì¹˜ë¥¼ ê¸°ë¡ : ë‹µë³€ ìµœëŒ€ ê¸¸ì´ë¥¼ ì œí•œ
    ).choices[0].message.content        # ì²«ë²ˆì§¸ ì‘ë‹µ í…ìŠ¤íŠ¸ 

# í…ìŠ¤íŠ¸ë¥¼ TTSë¡œ mp3ë¡œ ìƒì„± í›„ base64 ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def tts(response: str):
    filename = 'output.mp3'     # TTS ê²°ê³¼ mp3 íŒŒì¼ëª… ì§€ì •
    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì˜ TTS ìš”ì²­
    with client.audio.speech.with_streaming_response.create(
        model = 'tts-1',
        voice = 'alloy',     # ìŒì„± í†¤/ìºë¦­í„°
        input = response     # ìŒì„±ìœ¼ë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸
    ) as resp:
        resp.stream_to_file(filename)   # ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ mp3 íŒŒì¼ë¡œ ì €ì¥

    with open(filename, 'rb') as f:     # rb: ë¦¬ë“œë°”ì´ë„ˆë¦¬.  ìƒì„±ëœ mp3 íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ê¸°
        data = f.read()                 # mp3 ì´ì§„ ë°ì´í„° ì½ê¸°
        b64_encoded = base64.b64encode(data).decode()     # ë‘ê°€ì§€ ê³¼ì • : (1)ì´ì§„ ë°ì´í„° -> Base64 ì´ì§„  / (2) Base64 ì´ì§„ -> ë¬¸ìì—´

    os.remove(filename)     # ìƒì„±ëœ ì¶œë ¥ mp3 íŒŒì¼ ì‚­ì œ

    return b64_encoded      # base64 ë¬¸ìì—´ ë°˜í™˜ (ì›¹/ì•±ì—ì„œ ë°”ë¡œ ì¬ìƒìš©)

# ===========================================================================================================================
# ë°”ì´ë„ˆë¦¬(binary)ëŠ” ì‚¬ëŒì´ ì½ëŠ” ë¬¸ì(text)ê°€ ì•„ë‹ˆë¼, 0ê³¼ 1 (ë°”ì´íŠ¸)ë¡œ ëœ ì›ë³¸ ë°ì´í„°(ì»´í“¨í„°ê°€ ì´í•´í•˜ëŠ” ì–¸ì–´)
# ë°”ì´ë„ˆë¦¬ ëª¨ë“œ ('rb'): ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì§€ ì•Šê³ , 0ê³¼ 1ë¡œ ëœ ìˆëŠ” ê·¸ëŒ€ë¡œì˜ ì´ì§„ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸(bytes) ë‹¨ìœ„ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.
# mp3, jpg, png, pdf ê°™ì€ íŒŒì¼ì€ ëŒ€ë¶€ë¶„ ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ë‹¤.

# - í…ìŠ¤íŠ¸ í˜•ì‹ ('r') : ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ê¸€ì ë°ì´í„° (ì˜ˆ : "hello", JSON ë¬¸ìì—´, CSV ë‚´ìš©)
# - ë°”ì´ë„ˆë¦¬ í˜•ì‹ ('rb') : íŒŒì¼ ìì²´ì˜ ì›ë³¸ ë°”ì´íŠ¸ (byte) ë°ì´í„° (ì˜ˆ : mp3, jpg, png, pdf)

# 1. í…ìŠ¤íŠ¸ vs ë°”ì´ë„ˆë¦¬ ğŸ’¿
# í…ìŠ¤íŠ¸ ëª¨ë“œ ('r'): ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ê¸€ì(A, B, ê°€, ë‚˜)ë¡œ í•´ì„í•´ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ìš´ì˜ì²´ì œì— ë§ê²Œ ìë™ìœ¼ë¡œ ë°”ê¿”ì£¼ê¸°ë„ í•˜ì£ .
# ë°”ì´ë„ˆë¦¬ ëª¨ë“œ ('rb'): ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì§€ ì•Šê³ , 0ê³¼ 1ë¡œ ëœ ìˆëŠ” ê·¸ëŒ€ë¡œì˜ ì´ì§„ ë°ì´í„°ë¥¼ ë°”ì´íŠ¸(bytes) ë‹¨ìœ„ë¡œ ì½ì–´ì˜µë‹ˆë‹¤.


# ì—…ë¡œë“œëœ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜(STT)í•´ì„œ ë°˜í™˜í•˜ëŠ” í•¨SIUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUU
def stt_file(uploaded_file) -> str:
    transcription = client.audio.transcriptions.create(
        model="whisper-1",
        file=(uploaded_file.name, uploaded_file.getvalue()) # (íŒŒì¼ëª…, íŒŒì¼ë°”ì´íŠ¸) íŠœí”Œ
    )
    return transcription.text                   # STT ê²°ê³¼ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
